# 광고 클릭 이벤트 집계(ad click event aggregation system)
* 페이스북이나 구글 규모에 맞는 광고 클릭 이벤트 집계 시스템을 설계해보자
* 디지털 광고의 핵심 프로세스는 RTB(Real Time Bidding)이다
* RTB를 통해 광고가 나갈 지면(inventory)을 거래한다

![img.png](img.png)


## 1단계: 문제 이해 및 설계 범위 확정
* Q : 데이터의 입력은 어떤 형태로 이루어 지나요?
  * A : 여러 서버에 분산된 로그 파일로 존재합니다
* Q : 데이터의 양은 어느 정도 인가요?
  * A : 매일 10억 클릭이 발생하고 광고는 200만 회 게재됩니다. 수는 매년 30% 증가합니다
* Q : 어떤 질의를 지원해야 하나요?
  * A : 특정 광고에 대한 지난 M분간의 클릭 이벤트 수, 질의 기간과 광고 수가 변경 가능한 지난 1분간 가장 많이 클릭된 광고 100개, ip, user_id, country를 기준으로 상기 2개 질의 결과를 필터링 할 수 있어야 한다
* Q : 늦게 도착하는 이벤트나, 중복 이벤트, 시스템 복구에 대한 고려가 필요 할까요?
  * A : 필요합니다
* Q : 지연 시간 요건은 어떻습니까?
  * A : 모든 처리는 수 분 내에 이루어져야 합니다. RTB와 광고 클릭 집계의 요구는 분리해야 합니다

### 기능 요구사항
* 지난 M분 동안의 ad_id 클릭 수 집계
* 매분 가장 많이 클릭된 상위 100개 광고 아이디를 반환
* 다양한 속성에 따른 집계 필터링 지원
* 데이터의 양은 페이스북, 구글 규모

### 비기능 요구사항
* 집계 결과 정확성은 데이터가 RTB 및 광고 과금에 사용되므로 중요하다
* 지연되거나 중복된 이벤트를 적절히 처리할 수 있다
* reliability : 부분적인 장애는 감내할 수 있어야 함
* 지연 시간 요구사항: 전체 처리 시간은 최대 수 분을 넘지 않아야 함

### 개략적 추정
* DAU는 10억 명
* 사용자는 하루 평균 1개 광고를 클릭
* QPS = 10억 / 86400초(100000) = 10,000
* 최대 QPS는 다섯 배인 50,000으로 가정
* 클릭 이벤트 하나를 0.1KB 라고 하면 일 100GB, 월 3TB

## 2단계: 개략적 설계안 제시 및 동의 구하기 
### 질의 API 설계
* consumer app의 클라이언트는 일반적으로 제품의 최종 사용자이지만
* 이 경우는 dashboard를 사용하는 data scientist, product manager, 광고주가 된다
* 기능 요구 사항은 아래와 가타
  * 지난 M분 동안의 ad_id 클릭 수 집계
  * 매분 가장 많이 클릭된 상위 100개 광고 아이디를 반환
  * 다양한 속성에 따른 집계 필터링 지원

**API 1 : 지난 M분간 각 ad_id에 발생한 클릭 수 집계**

```
GET /v1/ads/{:ad_id}/aggregated_count
```
**params**
```

from : 집계 시작
to : 집계 종료
filter : 필터링 전략
```
**response**
```json
{
  "ad_id" : "ad_id",
  "count" : 123
}
```


**API 2 : 지난 M분간 각 ad_id에 발생한 클릭 수 집계**

```
GET /v1/ads/popular_ads
```
**params**
```
count : 상위 몇 개의 광고를 반환할 지
window : 분 단위로 표현된 집계 윈도 크기
filter : 필터링 전략
```
**response**
```json
{
  "ad_ids" : ["id1", "id2", "id3"]
}
```

### 데이터 모델
* 시스템의 데이터는 raw 데이터와 aggregated 데이터가 있다

| |               raw data                |    aggregated data     |
|:--:|:-------------------------------------:|:----------------------:|
|장점| 원본 데이터를 손실 없이 보관<br/>데이터 필터링 및 재계산 지원 | 데이터 용량 절감<br/>빠른 질의 성능 |
|단점|        막대한 데이터 용량<br/>낮은 질의 성능        |         데이터 손실         |

* 둘 다 저장을 해두자
* 문제 발생 시 디버깅이 필요하다
* raw data는 크기의 문제로 쿼리용으로 사용하긴 어렵다

### 올바른 데이터베이스의 선택
* 데이터의 형태를 살펴보면
* raw data의 경우 대부분은 쓰기 작업이다
  * 따라서 쓰기에 유리한 카산드라 또는 influxDB를 사용하는 것이 바람직 하다
  * S3와 같은 blob storage에 ORC, Parquet, AVRO와 같은 데이터 형식으로 저장하는 방법도 있다
* aggregated data의 경우 쓰기와 읽기가 모두 많이 발생한다

### 개략적 설계안
![img_1.png](img_1.png)

